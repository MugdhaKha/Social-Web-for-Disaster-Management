# Social Web for Disaster Management
Team Members: Mugdha Khatavkar, Shravan Manerikar, Nikita Salkar, Delstan D'Souza

This study employs unsupervised clustering and deep learning techniques for the same purpose of classifying tweets into need tweets and availability tweets.

The steps taken to accomplish the required tasks were as follows:

a) Extracting thousands of tweets that were relevant to the disaster.
b) Preprocessing the tweets, removing emoticons, abbreviations etc., multi-lingual tweets while keeping only English.
c) Transforming the tweets into vector representation.
d) Implementing clustering techniques to cluster into need tweets and availability tweets.
e) Deep learning.

In order to retrieve the tweets, the Twitter API is used to gain access to the tweets. Analysis of the information retrieved from the dataset requires categorization, cleaning and understanding before it is put to use. The data retrieved from the social media for the purpose of disaster relief first needs to be pre-processed to filter out unwanted data. Preprocessing techniques are used to clean and make the tweets, written in social media jargons, appropriate for use. The preprocessed tweets need to be segregated into need-tweets and availability-tweets. We then explore clustering techniques and deep learning methods with a focus on facilitating the same. Thus, the principal objective of this study is classifying the extracted tweets during an on-going crisis into need-tweets and availability-tweets with a focus on linking the two. This linking of tweets will help the Government formulate a formative solution and to bring order from chaos. It will also give organizations direction in which to proceed speedily and help save time to extend their help and will channelize the coordination between emergency requests and relief offers.

For more information read the Report.pdf
